# Requirement specification

A simple feedforward multilayer neural network with backpropagation for classifying images in the Mnist dataset. 

- The hidden layers are activated by rectified linear unit (ReLU)
- The output layer is activated by softmax function 
- Most of the project will be implemented from scratch except matrix operations will be done with numpy 
- Training will be conducted through a standard gradient descent 
- The training data (input) will be a part of the Mnist dataset and output will be the inferred digit

I intend to use Michael A. Nielsens "Neural Networks and Deep Learning", Determination Press, 2015 as a guide in my work.

## Time complexity

The time complexity of neural networks seems to be a topic of its own and I try to update this section as I get a better grasp of the subject.  
