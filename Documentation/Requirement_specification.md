# Requirement specification

A simple program to create and train feedforward multilayer neural networks for classifying images in the Mnist dataset. The user will be able to choose the amount of hidden layers and the amount of neurons in the layers. The user can set various hyperparameters for the training phase such as mini batch size, amount of epochs, learning rate and L2 regularization parameter.   

Main features
- The activation function for the neurons is a sigmoid function 
- The cost function is a cross entropy cost funtion
- During training the weights and biases are updated with the stochastic gradient descent and the gradient is computed with backpropagation

I intend to use Michael A. Nielsens "Neural Networks and Deep Learning", Determination Press, 2015 as a guide in my work.

## Time complexity

The time complexity of neural networks seems to be a topic of its own and I try to update this section as I get a better grasp of the subject.  
