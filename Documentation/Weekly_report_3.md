This week’s hours were mostly spent trying to understand the math behind gradient descent and backpropagation. Especially understanding backpropagation took a lot of time as I cannot say that I’m very good in calculus and I really cannot say that I fully understand it. But I kind of understand what the code does. I finished a working version of the algorithm and the trained network now manages to classify the dataset quite well. I wrote tests for some parts of the code but got stuck trying to figure out how to test the gradient descent and backpropagation. I will probably need to divide them to smaller pieces for testing. The rest of the week was spent on researching out some kind of CI and test coverage/style check solutions for python. There is now badges in the GitHub pages which lead to codecov for test coverage reports and codeclimate for static code analysis. I used github actions for running the tests and it worked really well. The github actions also run flake8 linting which produces an error if there is some major problem with the code. I couldn’t figure out how to automatically upload reports online from flake8, so I chose to use clodeclimate with pep8 plugin. Next week I will try to write tests for the rest of the code and start optimizing the network according to the book I’m using. I used around 20 hours this week most of it on trying to understand the math.
